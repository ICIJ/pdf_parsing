{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afddb81e0a51f08c",
   "metadata": {},
   "source": "# Parsing PDFs on a laptop (or on-premise)"
  },
  {
   "cell_type": "markdown",
   "id": "506a8e1e731169dc",
   "metadata": {},
   "source": [
    "# Reminder: PDF parsing workflow\n",
    "<div style=\"background-color:white;text-align: center;\">\n",
    "    <img src=\"../data/presentation/pdf_parsing_flow.svg\" alt=\"pdf_parsing_flow\" style=\"width:800px;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0826e128c3c1919",
   "metadata": {},
   "source": "## Common stuff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0858aa7f1232e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT_PATH = Path(\".\").absolute().parent\n",
    "DATA_PATH = ROOT_PATH / \"data\"\n",
    "OUTPUT_PATH = DATA_PATH / \"outputs\"\n",
    "NOTEBOOKS_PATH = ROOT_PATH / \"pdf_parsing\"\n",
    "EXAMPLES_PATH = DATA_PATH / \"examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3749b4582e53629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import transformers\n",
    "from IPython.display import IFrame, Markdown\n",
    "from pdf_parsing.logging_utils import set_loggers_if_needed\n",
    "import docling\n",
    "import camelot\n",
    "import marker\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "set_loggers_if_needed(\n",
    "    [\n",
    "        transformers.__name__,\n",
    "        logger.name,\n",
    "        torch.__name__,\n",
    "        docling.__name__,\n",
    "        camelot.__name__,\n",
    "        marker.__name__,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e291dd24b598ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_ARTICLE = \"sample_article.pdf\"\n",
    "SAMPLE_INVOICE = \"sample_invoice.pdf\"\n",
    "SAMPLE_SCANNED_TABLE = \"sample_scanned_table.pdf\"\n",
    "\n",
    "ARTICLE_PATH = EXAMPLES_PATH / SAMPLE_ARTICLE\n",
    "INVOICE_PATH = EXAMPLES_PATH / SAMPLE_INVOICE\n",
    "SCANNED_TABLE_PATH = EXAMPLES_PATH / SAMPLE_SCANNED_TABLE\n",
    "\n",
    "# IFrames path must be relative to the current HTML page, which is this doc\n",
    "REL_EXAMPLES_PATH = Path(\"..\", \"data\", \"examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e69ec8c1438467",
   "metadata": {},
   "source": "## [Camelot](https://camelot-py.readthedocs.io/en/master/)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc665051022689ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def camelot_tables(pdf_path: Path) -> list[pd.DataFrame]:\n",
    "    tables = camelot.read_pdf(pdf_path)\n",
    "    return [t.df for t in tables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a3dfe32a9567d5",
   "metadata": {},
   "source": [
    "## [MarkerPDF](https://github.com/datalab-to/marker)\n",
    "\n",
    "Marker works very well with the base config.\n",
    "\n",
    "We can easily export documents as markdowns, however there's no native way to get CSV or Dataframe for tables, we hence parse the markdown document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea45cd70a0ee006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from typing import Any\n",
    "from marker.output import text_from_rendered\n",
    "from marker.models import create_model_dict\n",
    "from marker.config.parser import ConfigParser\n",
    "from marker.converters.pdf import PdfConverter\n",
    "\n",
    "MD_HEADER_SEP_RE = re.compile(r\"^\\|[\\s\\-\\|:]+\\|$\")\n",
    "MD_TABLE_RE = re.compile(r\"(\\|.*\\|(?:\\n\\|.*\\|)*)\")\n",
    "\n",
    "\n",
    "def marker_markdown(pdf_path: Path, config: dict[str, Any] = None) -> tuple[str, dict]:\n",
    "    if config is None:\n",
    "        config = dict()\n",
    "    config[\"output_format\"] = \"markdown\"\n",
    "    config_parser = ConfigParser(config)\n",
    "    renderer = config_parser.get_renderer()\n",
    "    converter = PdfConverter(\n",
    "        config=config_parser.generate_config_dict(),\n",
    "        artifact_dict=create_model_dict(),\n",
    "        processor_list=config_parser.get_processors(),\n",
    "        renderer=renderer,\n",
    "    )\n",
    "    parsed = converter(str(pdf_path))\n",
    "    content, _, images = text_from_rendered(parsed)\n",
    "    return content, images\n",
    "\n",
    "\n",
    "def md_to_dfs(md_content: str) -> list[pd.DataFrame]:\n",
    "    dfs = [\n",
    "        _md_table_to_df(md_table.string)\n",
    "        for md_table in MD_TABLE_RE.finditer(md_content)\n",
    "    ]\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def _md_table_to_df(md_table: str) -> pd.DataFrame:\n",
    "    lines = (line.strip() for line in md_table.strip().split(\"\\n\"))\n",
    "    lines = (line for line in lines if not MD_HEADER_SEP_RE.match(line))\n",
    "    rows = []\n",
    "    for line in lines:\n",
    "        if line.startswith(\"|\") and line.endswith(\"|\"):\n",
    "            cells = [cell.strip() for cell in line[1:-1].split(\"|\")]\n",
    "            rows.append(cells)\n",
    "    df = pd.DataFrame(rows[1:], columns=rows[0])\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_marker_markdown(content: str, images: dict, *, path: Path):\n",
    "    if not images:\n",
    "        path.write_text(content)\n",
    "    else:\n",
    "        # If the Markdown contains image, create a directory and save\n",
    "        # them inside. They will be referenced in the markdown\n",
    "        markdown_dir = path.with_name(path.with_suffix(\"\").name)\n",
    "        markdown_dir.mkdir(parents=True, exist_ok=True)\n",
    "        content_path = markdown_dir / path.name\n",
    "        content_path.write_text(content)\n",
    "        for im_name, im in images.items():\n",
    "            im.save(str(markdown_dir / im_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7727426e4c5d10b",
   "metadata": {},
   "source": [
    "## [Docling](https://docling-project.github.io/docling/)\n",
    "\n",
    "With docling we can get the parse PDF as a `DoclingDocument` and then easily convert it to Markdown or Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d85df2ef7f7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling_core.types import DoclingDocument\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "\n",
    "DOCLING_DEFAULT_OPTS = {\n",
    "    InputFormat.PDF: PdfFormatOption(\n",
    "        pipeline_options=PdfPipelineOptions(generate_picture_images=True)\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "def docling_parsing(\n",
    "    pdf_path: Path, format_options: dict[InputFormat, PdfFormatOption] = None\n",
    ") -> DoclingDocument:\n",
    "    if format_options is None:\n",
    "        format_options = DOCLING_DEFAULT_OPTS\n",
    "    converter = DocumentConverter(format_options=format_options)\n",
    "    result = converter.convert(pdf_path)\n",
    "    return result.document\n",
    "\n",
    "\n",
    "def docling_doc_to_dfs(doc: DoclingDocument) -> list[pd.DataFrame]:\n",
    "    return [table.export_to_dataframe() for table in doc.tables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f3ee9ba50a9c37",
   "metadata": {},
   "source": "Docling base config use EasyOCR. Using the following config is equivalent to `docling my_doc.pdf`:"
  },
  {
   "cell_type": "markdown",
   "id": "fe2052f900ff4a2a",
   "metadata": {},
   "source": "Docling is very configurable we can define use a few different configs."
  },
  {
   "cell_type": "markdown",
   "id": "70298f0e65c5070d",
   "metadata": {},
   "source": [
    "### Docling + [tesseract](https://tesseract-ocr.github.io/tessdoc/) as OCR (installation required)\n",
    "\n",
    "Docling runs with EasyOCR by default, to improve perfs and speedup we can use tesseract.\n",
    "Using the following config is equivalent to `docling --ocr-engine tesseract --ocr-lang auto my_doc.pdf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618a4343f824ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.pipeline_options import TesseractOcrOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "\n",
    "DOCLING_TESSERACT_OPTS = {\n",
    "    InputFormat.PDF: PdfFormatOption(\n",
    "        pipeline_options=PdfPipelineOptions(\n",
    "            generate_picture_images=True,\n",
    "            ocr_options=TesseractOcrOptions(lang=[\"auto\"]),\n",
    "        ),\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b2b9f240b683e6",
   "metadata": {},
   "source": [
    "### Docling + VLMs\n",
    "\n",
    "We can also use Docling with a small SmolDocling VLM. Using the following config is equivalent to `docling --pipeline vlm --vlm-model smoldocling my_doc.pdf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82af7dc1425cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "from docling.datamodel.vlm_model_specs import (\n",
    "    QWEN25_VL_3B_MLX,\n",
    "    SMOLDOCLING_MLX,\n",
    "    SMOLDOCLING_TRANSFORMERS,\n",
    ")\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "\n",
    "if platform.system() == \"Darwin\":  # Additional speedups on MacOS\n",
    "    smol_vlm_options = SMOLDOCLING_MLX\n",
    "else:\n",
    "    smol_vlm_options = SMOLDOCLING_TRANSFORMERS\n",
    "\n",
    "DOCLING_SMOL_OPTS = {\n",
    "    InputFormat.PDF: PdfFormatOption(\n",
    "        pipeline_cls=VlmPipeline,\n",
    "        pipeline_options=VlmPipelineOptions(vlm_options=smol_vlm_options),\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34cf59ef1e59146",
   "metadata": {},
   "source": "We can also use larger VLMs like QWEN2.5B on MacOS . Using the following config is equivalent to `docling --pipeline vlm --vlm-model qwen25_vl_3b_mlx my_doc.pdf`:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed74515064d9f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the accelerated/MLX Qwen model is only available on MacOS\n",
    "if platform.system() == \"Darwin\":\n",
    "    DOCLING_QWEN_OPTS = {\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=VlmPipelineOptions(vlm_options=QWEN25_VL_3B_MLX),\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdfae2708670c92",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "## Example 1: article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b811dc34d16c0e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(REL_EXAMPLES_PATH / SAMPLE_ARTICLE, width=1200, height=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c156493ccf744b",
   "metadata": {},
   "source": "The PDF is computer-generated with no complex layout element we can go for level-0 or level-1 tools."
  },
  {
   "cell_type": "markdown",
   "id": "3b667597cd393aed",
   "metadata": {},
   "source": "## Example 1 - level 1: Camelot"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e291fab85603c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_OUTPUT_PATH = OUTPUT_PATH / \"article\"\n",
    "ARTICLE_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e9cc05959d736",
   "metadata": {},
   "source": "Let's try to extract the table using Camelot first:\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abd7bbfeec5989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_camelot_tables = camelot_tables(ARTICLE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d923c5df8e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(article_camelot_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3efaec8f1203727",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_camelot_df = article_camelot_tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1c4cb0bb25dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_camelot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2fa8ebc2128b6c",
   "metadata": {},
   "source": "After some post-processing, we can easily get the proper table:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcbddff843de51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_camelot_df = article_camelot_df.replace(\"\\n\", \"\", regex=True)\n",
    "article_camelot_df.iloc[0, 3] = \"\"\n",
    "article_camelot_df.iloc[0] += article_camelot_df.iloc[1]\n",
    "article_camelot_df = article_camelot_df.set_axis(\n",
    "    article_camelot_df.iloc[0].tolist(), axis=\"columns\"\n",
    ")\n",
    "article_camelot_df.drop([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0299c2befb1b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_camelot_df.to_csv(ARTICLE_OUTPUT_PATH / \"camelot_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ef6c49f42779b7",
   "metadata": {},
   "source": [
    "Camelot performs nicely on this table, however it can only output tables, not the full document. Let's see how level 2 tools perform.\n",
    "\n",
    "## Example 1 - level 2: Marker and Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b581ca3be994abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_marker_md, article_marker_images = marker_markdown(ARTICLE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d644d74c62a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(article_marker_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d7ec72ffe6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_marker_dfs = md_to_dfs(article_marker_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58ef96752f5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(article_marker_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d26a17070f0dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_marker_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c924b343d81102",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_marker_df = article_marker_dfs[0]\n",
    "new_columns = (\n",
    "    article_marker_df.columns[:3].tolist() + article_marker_df.iloc[0, 3:].tolist()\n",
    ")\n",
    "new_columns = [c.replace(\"<br>\", \" \") for c in new_columns]\n",
    "article_marker_df = article_marker_df.set_axis(new_columns, axis=\"columns\")\n",
    "article_marker_df.drop([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5348321c0dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_marker_df.to_csv(ARTICLE_OUTPUT_PATH / \"marker_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6edabd8c12017a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_marker_markdown(\n",
    "    article_marker_md, article_marker_images, path=ARTICLE_OUTPUT_PATH / \"marker.md\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432773f4fb59108d",
   "metadata": {},
   "source": "This looks great nice, see what Docling does:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca1a66a5025adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_docling_doc = docling_parsing(ARTICLE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a9192be766cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_docling_md = article_docling_doc.export_to_markdown()\n",
    "Markdown(article_docling_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec39162745abf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_docling_dfs = docling_doc_to_dfs(article_docling_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c94a6a122e09c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(article_docling_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38b4cc05da879b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_docling_df = article_docling_dfs[0]\n",
    "article_docling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1a2496b7955c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_docling_df.to_csv(ARTICLE_OUTPUT_PATH / \"docling_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4953c232a02b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ARTICLE_OUTPUT_PATH / \"docling.md\").write_text(article_docling_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e59e238690bfd",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- both Camelot, Marker and Docling provide decent table parsing results\n",
    "- Docling properly handles subcolumns, and requires no post-processing\n",
    "- Marker and Docling additionally allow parsing the full document (not only the table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f17c92a207a9b72",
   "metadata": {},
   "source": "## Example 2: invoice"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9185da6d6b987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(REL_EXAMPLES_PATH / SAMPLE_INVOICE, width=1200, height=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f894ea5f81169a40",
   "metadata": {},
   "source": [
    "The invoice is computer generated. Its layout is quite simple in appearance, however, the **document layout is not trivial, and the table is quite implicit:\n",
    "We must use level-2 libs at least**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd8da0c6c2d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "INVOICE_OUTPUT_PATH = OUTPUT_PATH / \"invoice\"\n",
    "INVOICE_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4dbe81bb15820",
   "metadata": {},
   "source": "## Example 2: Marker"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff6d2b3c632cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_marker_md, invoice_marker_md_images = marker_markdown(INVOICE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c790134edd086a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(invoice_marker_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8baa23f619cb4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_marker_markdown(\n",
    "    invoice_marker_md, invoice_marker_md_images, path=INVOICE_OUTPUT_PATH / \"marker.md\"\n",
    ")\n",
    "md_to_dfs(invoice_marker_md)[0].to_csv(INVOICE_OUTPUT_PATH / \"marker_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108119a2351c9685",
   "metadata": {},
   "source": [
    "If we look at the actual [markdown output](../data/outputs/invoice/marker/marker.md), it's almost perfect !\n",
    "\n",
    "## Example 2: Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e74aaa62d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_docling_doc = docling_parsing(INVOICE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d525ae274bc5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling_core.types.doc import ImageRefMode\n",
    "\n",
    "invoice_docling_doc_md = invoice_docling_doc.export_to_markdown(\n",
    "    image_mode=ImageRefMode.EMBEDDED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69363a936824cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(invoice_docling_doc_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8119c7b493662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_docling_doc.save_as_markdown(\n",
    "    INVOICE_OUTPUT_PATH / \"docling.md\", image_mode=ImageRefMode.EMBEDDED\n",
    ")\n",
    "invoice_docling_doc.tables[0].export_to_dataframe().to_csv(\n",
    "    INVOICE_OUTPUT_PATH / \"docling_table.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3d513d766e89fb",
   "metadata": {},
   "source": "If we look at the actual [markdown output](../data/outputs/invoice/docling.md), the table is perfectly extracted, the document layout is however not as clean as with Marker."
  },
  {
   "cell_type": "markdown",
   "id": "367e018a17348947",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- both Marker and Docling (base configuration) get the table right\n",
    "- Marker does a better job at preserving the document content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48e703be7d0511c",
   "metadata": {},
   "source": "# Example 3: scanned table"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453c27779d3394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(REL_EXAMPLES_PATH / SAMPLE_SCANNED_TABLE, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba98b17eafd1c24",
   "metadata": {},
   "source": "We have a scanned table, level 3 tools are recommended."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c126319726f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCANNED_TABLE_OUTPUT_PATH = OUTPUT_PATH / \"scanned_table\"\n",
    "SCANNED_TABLE_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cd7901d0899852",
   "metadata": {},
   "source": "## Examples 3: Docling VLMs\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4050460913dc30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanned_table_docling_smol_doc = docling_parsing(SCANNED_TABLE_PATH, DOCLING_SMOL_OPTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d838b459c3a6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanned_table_docling_smol_md = scanned_table_docling_smol_doc.export_to_markdown()\n",
    "Markdown(scanned_table_docling_smol_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382bc2c8661861b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(SCANNED_TABLE_OUTPUT_PATH / \"docling_smol.md\").write_text(\n",
    "    scanned_table_docling_smol_md\n",
    ")\n",
    "scanned_table_docling_smol_doc.tables[0].export_to_dataframe().to_csv(\n",
    "    SCANNED_TABLE_OUTPUT_PATH / \"docling_smol_table.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b52497f4ed24022",
   "metadata": {},
   "source": "Columns, get mixed up, let's try a larger VLM:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5227660f08516be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanned_table_docling_qwen_doc = docling_parsing(SCANNED_TABLE_PATH, DOCLING_QWEN_OPTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d07ee4c8f5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanned_table_docling_qwen_md = scanned_table_docling_qwen_doc.export_to_markdown()\n",
    "Markdown(scanned_table_docling_qwen_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2082a9e664c5596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(SCANNED_TABLE_OUTPUT_PATH / \"docling_qwen.md\").write_text(\n",
    "    scanned_table_docling_qwen_md\n",
    ")\n",
    "scanned_table_docling_qwen_doc.tables[0].export_to_dataframe().to_csv(\n",
    "    SCANNED_TABLE_OUTPUT_PATH / \"docling_qwen_table.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75164ffd60dbd137",
   "metadata": {},
   "source": [
    "## Examples 3: [OlmOCR](https://olmocr.allenai.org/)\n",
    "\n",
    "Let's upload or doc to [OlmOCR](https://olmocr.allenai.org/), we get the following output:\n",
    "\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>LÉGUMINEUSE</th>\n",
    "<th>TREMPAGE</th>\n",
    "<th>CUISSON (à partir de l&#39;ébullition)</th>\n",
    "<th>VOLUME D&#39;EAU pour 1 volume de légumineuses à ajouter à la cuisson</th>\n",
    "<th>QUANTITÉ par personne</th>\n",
    "<th>CUISSON sans trempage</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody><tr>\n",
    "<td>Haricots azukis</td>\n",
    "<td>12 h</td>\n",
    "<td>1 h</td>\n",
    "<td>2,5</td>\n",
    "<td>60 g</td>\n",
    "<td>1 h 30</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Haricots (cocos, noirs, rouges, blancs...)</td>\n",
    "<td>12 h</td>\n",
    "<td>1 h</td>\n",
    "<td>2,5</td>\n",
    "<td>60 g</td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Haricots mungos</td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "<td>2,5</td>\n",
    "<td>60 g</td>\n",
    "<td>2 h</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Flageolets</td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "<td>2,5</td>\n",
    "<td>60 g</td>\n",
    "<td>1 h 30</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Lentilles vertes</td>\n",
    "<td>4 h</td>\n",
    "<td>30 min</td>\n",
    "<td>2,5</td>\n",
    "<td>60 g</td>\n",
    "<td>45 min</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Lentilles corail</td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "<td>60 g</td>\n",
    "<td>10 à 15 min</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Pois cassés</td>\n",
    "<td>2 h</td>\n",
    "<td>30 min</td>\n",
    "<td>2</td>\n",
    "<td>100 g (purée) 80 g (soupe)</td>\n",
    "<td>1 h</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Pois chiches</td>\n",
    "<td>12 h</td>\n",
    "<td>1 h</td>\n",
    "<td>2,5</td>\n",
    "<td>60 g</td>\n",
    "<td></td>\n",
    "</tr>\n",
    "</tbody></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184f21c80c698a9",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- Docling-Smol mixes up some columns\n",
    "- Docling-Qwen get the table right\n",
    "- OlmOCR also mixes up somes columsn\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
